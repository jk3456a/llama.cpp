#!/usr/bin/env python3
"""
GGUFæ¨¡å‹åŸºå‡†æµ‹è¯•è„šæœ¬
è‡ªåŠ¨æµ‹è¯•æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰*.ggufæ¨¡å‹æ–‡ä»¶
æ”¯æŒCPUå’ŒGPUæµ‹è¯•ï¼Œæ’é™¤æœ‰é—®é¢˜çš„TQé‡åŒ–æ¨¡å‹çš„GPUæµ‹è¯•
"""

import os
import subprocess
import csv
import json
import sys
import re
from datetime import datetime
from pathlib import Path

# é…ç½®å‚æ•°
MODEL_DIR = "/Users/yummy/workspace/models"
LLAMA_BENCH_PATH = "./tools/llama-bench/llama-bench"  # llama-benchå·¥å…·è·¯å¾„
CONTEXT_LENGTHS = [1024, 2048, 4096]  # æµ‹è¯•çš„ä¸Šä¸‹æ–‡é•¿åº¦
N_GEN = 16  # ç”Ÿæˆtokenæ•°é‡
REPETITIONS = 1  # é‡å¤æ¬¡æ•°
FLASH_ATTN = 1  # å¯ç”¨flash attention

def find_gguf_files(directory):
    """æŸ¥æ‰¾æŒ‡å®šç›®å½•ä¸‹æ‰€æœ‰çš„.ggufæ–‡ä»¶"""
    if not os.path.exists(directory):
        print(f"è­¦å‘Š: ç›®å½•ä¸å­˜åœ¨: {directory}")
        return []
    
    gguf_files = []
    try:
        for root, dirs, files in os.walk(directory):
            for file in files:
                if file.endswith('.gguf'):
                    full_path = os.path.join(root, file)
                    gguf_files.append(full_path)
                    print(f"å‘ç°æ¨¡å‹: {file}")
    except Exception as e:
        print(f"æœç´¢æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    return gguf_files

def should_test_gpu(model_path):
    """åˆ¤æ–­æ¨¡å‹æ˜¯å¦åº”è¯¥åœ¨GPUä¸Šæµ‹è¯•"""
    model_name = os.path.basename(model_path).upper()
    # TQé‡åŒ–æ¨¡å‹åœ¨Metalåç«¯æœ‰å…¼å®¹æ€§é—®é¢˜ï¼Œåªåœ¨CPUä¸Šæµ‹è¯•
    if "TQ" in model_name:
        return False
    return True

def run_benchmark(model_path, context_length, use_gpu=True):
    """è¿è¡Œå•ä¸ªæ¨¡å‹çš„åŸºå‡†æµ‹è¯•"""
    # Q4_0æ¨¡å‹ä½¿ç”¨æ›´å¤šé‡å¤æ¬¡æ•°ä»¥è·å¾—æ›´ç¨³å®šçš„ç»“æœ
    model_name = os.path.basename(model_path).upper()
    repetitions = 5 if "Q4_0" in model_name else REPETITIONS
    
    cmd = [
        LLAMA_BENCH_PATH,
        "-m", model_path,
        "-fa", str(FLASH_ATTN),
        "-d", str(context_length),
        "-n", str(N_GEN),
        "-r", str(repetitions),
        "-t", "4"
    ]
    
    # å¦‚æœæ˜¯CPUæµ‹è¯•ï¼Œæ·»åŠ -ngl 0å‚æ•°
    if not use_gpu:
        cmd.extend(["-ngl", "0"])
    
    backend_type = "GPU" if use_gpu else "CPU"
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    env = os.environ.copy()
    env["QOS_CLASS_USER_INTERACTIVE"] = "1"
    
    try:
        print(f"è¿è¡Œæµ‹è¯•: {os.path.basename(model_path)} | {backend_type} | ä¸Šä¸‹æ–‡: {context_length}")
        print(f"å‘½ä»¤: QOS_CLASS_USER_INTERACTIVE=1 {' '.join(cmd)}")
        
        result = subprocess.run(cmd, capture_output=True, text=True, env=env)
        
        if result.returncode == 0:
            print(f"âœ“ æµ‹è¯•æˆåŠŸ")
            # è¾“å‡ºåŸå§‹æ•°æ®ç”¨äºè°ƒè¯•
            print("--- åŸå§‹è¾“å‡º ---")
            print(result.stdout)
            print("--- åŸå§‹è¾“å‡ºç»“æŸ ---")
            return result.stdout, backend_type, N_GEN, repetitions
        else:
            print(f"âœ— æµ‹è¯•å¤±è´¥: {result.stderr}")
            return None, backend_type, N_GEN, repetitions
    except FileNotFoundError:
        print(f"âœ— æ‰¾ä¸åˆ°llama-benchå·¥å…·: {LLAMA_BENCH_PATH}")
        return None, backend_type, N_GEN, repetitions
    except Exception as e:
        print(f"âœ— è¿è¡Œæµ‹è¯•æ—¶å‡ºé”™: {e}")
        return None, backend_type, N_GEN, repetitions

def extract_tokens_per_second(output):
    """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–tokens/sæ•°æ®"""
    if not output:
        return []
    
    results = []
    try:
        # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…tokens/sæ•°æ®
        pattern = r'(\d+\.\d+)\s*Â±\s*(\d+\.\d+)'
        matches = re.findall(pattern, output)
        
        # åŒ¹é…æµ‹è¯•ç±»å‹ pp512 @ d1024 æˆ– tg16 @ d1024
        test_pattern = r'(pp\d+|tg\d+)\s*@\s*d(\d+)'
        test_matches = re.findall(test_pattern, output)
        
        print(f"æ‰¾åˆ° {len(matches)} ä¸ªæ€§èƒ½æ•°æ®åŒ¹é…")
        print(f"æ‰¾åˆ° {len(test_matches)} ä¸ªæµ‹è¯•ç±»å‹åŒ¹é…")
        
        # é…å¯¹æ€§èƒ½æ•°æ®å’Œæµ‹è¯•ç±»å‹
        for i, (avg_ts, stddev_ts) in enumerate(matches):
            result = {}
            result['avg_ts'] = float(avg_ts)
            result['stddev_ts'] = float(stddev_ts)
            
            if i < len(test_matches):
                test_type, context = test_matches[i]
                result['test_type'] = test_type
                result['context_length'] = int(context)
                
                if test_type.startswith('pp'):
                    result['phase'] = 'prompt_processing'
                elif test_type.startswith('tg'):
                    result['phase'] = 'token_generation'
            
            results.append(result)
            
    except Exception as e:
        print(f"æ­£åˆ™è¡¨è¾¾å¼è§£æå‡ºé”™: {e}")
    
    return results

def format_size(size_bytes):
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    if isinstance(size_bytes, (int, float)) and size_bytes > 0:
        return f"{size_bytes / (1024**3):.2f} GiB"
    return "N/A"

def format_params(params):
    """æ ¼å¼åŒ–å‚æ•°æ•°é‡"""
    if isinstance(params, (int, float)) and params > 0:
        if params >= 1e9:
            return f"{params / 1e9:.2f} B"
        elif params >= 1e6:
            return f"{params / 1e6:.2f} M"
        else:
            return f"{params / 1e3:.2f} K"
    return "N/A"

# CSVæ–‡ä»¶å
CSV_FILENAME = "benchmark_results.csv"

def load_existing_results():
    """åŠ è½½å·²å­˜åœ¨çš„æµ‹è¯•ç»“æœ"""
    existing_tests = set()
    
    if not os.path.exists(CSV_FILENAME):
        return existing_tests
    
    try:
        with open(CSV_FILENAME, 'r', encoding='utf-8') as csvfile:
            reader = csv.DictReader(csvfile)
            for row in reader:
                # åˆ›å»ºå”¯ä¸€æ ‡è¯†ç¬¦ï¼šæ¨¡å‹å_åç«¯_ä¸Šä¸‹æ–‡é•¿åº¦
                test_key = f"{row['model_name']}_{row['backend']}_{row['context_length']}"
                existing_tests.add(test_key)
        
        print(f"ä»CSVæ–‡ä»¶åŠ è½½äº† {len(existing_tests)} ä¸ªå·²å®Œæˆçš„æµ‹è¯•é…ç½®")
        
    except Exception as e:
        print(f"è¯»å–CSVæ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    return existing_tests

def is_test_already_done(model_name, backend, context_length, existing_tests):
    """æ£€æŸ¥æµ‹è¯•æ˜¯å¦å·²ç»å®Œæˆ"""
    test_key = f"{model_name}_{backend}_{context_length}"
    return test_key in existing_tests

def save_to_csv(row_data):
    """ç«‹å³ä¿å­˜ä¸€è¡Œæ•°æ®åˆ°CSVæ–‡ä»¶"""
    try:
        file_exists = os.path.exists(CSV_FILENAME)
        
        with open(CSV_FILENAME, 'a', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['model_name', 'backend', 'n_gen', 'repetitions', 'context_length', 'phase', 'tokens_per_sec']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            if not file_exists:
                writer.writeheader()
                print(f"åˆ›å»ºCSVæ–‡ä»¶: {CSV_FILENAME}")
            
            writer.writerow(row_data)
            
    except Exception as e:
        print(f"ä¿å­˜CSVæ—¶å‡ºé”™: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("=== GGUFæ¨¡å‹åŸºå‡†æµ‹è¯•å·¥å…· ===")
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    print(f"å½“å‰ç›®å½•: {os.getcwd()}")
    print("")
    
    # æ£€æŸ¥llama-benchæ˜¯å¦å­˜åœ¨
    if not os.path.exists(LLAMA_BENCH_PATH):
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°llama-benchå·¥å…·: {LLAMA_BENCH_PATH}")
        print("è¯·å…ˆç¼–è¯‘llama-benchå·¥å…·")
        return False
    
    # æŸ¥æ‰¾æ‰€æœ‰GGUFæ–‡ä»¶
    print(f"åœ¨ç›®å½• {MODEL_DIR} ä¸­æŸ¥æ‰¾GGUFæ–‡ä»¶...")
    gguf_files = find_gguf_files(MODEL_DIR)
    
    if not gguf_files:
        print(f"åœ¨ {MODEL_DIR} ä¸­æœªæ‰¾åˆ°ä»»ä½•.ggufæ–‡ä»¶")
        return False
    
    print(f"\næ‰¾åˆ° {len(gguf_files)} ä¸ªGGUFæ–‡ä»¶")
    
    # è®¡ç®—æ€»æµ‹è¯•æ•°
    total_tests = 0
    for model_path in gguf_files:
        if should_test_gpu(model_path):
            total_tests += len(CONTEXT_LENGTHS) * 2  # CPUå’ŒGPU
        else:
            total_tests += len(CONTEXT_LENGTHS)  # åªæœ‰CPU
    
    print(f"è®¡åˆ’è¿›è¡Œ {total_tests} ä¸ªåŸºå‡†æµ‹è¯•")
    print("")
    
    # åŠ è½½å·²å­˜åœ¨çš„æµ‹è¯•ç»“æœ
    existing_tests = load_existing_results()
    
    # å­˜å‚¨æ‰€æœ‰æµ‹è¯•ç»“æœ
    all_results = []
    current_test = 0
    skipped_tests = 0
    
    # å¯¹æ¯ä¸ªæ¨¡å‹è¿è¡Œæµ‹è¯•
    for model_path in gguf_files:
        model_name = os.path.basename(model_path)
        print(f"\n--- æµ‹è¯•æ¨¡å‹: {model_name} ---")
        
        # åˆ¤æ–­æ˜¯å¦æµ‹è¯•GPU
        test_gpu = should_test_gpu(model_path)
        
        if not test_gpu:
            print(f"âš ï¸  {model_name} åŒ…å«TQé‡åŒ–ï¼Œè·³è¿‡GPUæµ‹è¯•")
        
        for context_length in CONTEXT_LENGTHS:
            # CPUæµ‹è¯•
            current_test += 1
            backend_type = "CPU"
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»æµ‹è¯•è¿‡
            if is_test_already_done(model_name, backend_type, context_length, existing_tests):
                print(f"\nè¿›åº¦: {current_test}/{total_tests} - â­ï¸ è·³è¿‡å·²å®Œæˆçš„æµ‹è¯•: {model_name} | {backend_type} | ä¸Šä¸‹æ–‡:{context_length}")
                skipped_tests += 1
            else:
                print(f"\nè¿›åº¦: {current_test}/{total_tests}")
                
                output, backend_type, n_gen, repetitions = run_benchmark(model_path, context_length, use_gpu=False)
                if output:
                    results = extract_tokens_per_second(output)
                    print(f"ğŸ“Š {model_name} | {backend_type} | ä¸Šä¸‹æ–‡:{context_length}")
                    for result in results:
                        tokens_per_sec = result.get('avg_ts', 0)
                        phase = result.get('phase', 'unknown')
                        print(f"   {phase}: {tokens_per_sec:.2f} t/s")
                        
                        # ç«‹å³ä¿å­˜åˆ°CSV
                        csv_row = {
                            'model_name': model_name,
                            'backend': backend_type,
                            'n_gen': n_gen,
                            'repetitions': repetitions,
                            'context_length': context_length,
                            'phase': phase,
                            'tokens_per_sec': tokens_per_sec
                        }
                        save_to_csv(csv_row)
                        all_results.append(csv_row)
                else:
                    print("æœªè·å–åˆ°è¾“å‡ºæ•°æ®")
            
            # GPUæµ‹è¯•ï¼ˆå¦‚æœæ”¯æŒï¼‰
            if test_gpu:
                current_test += 1
                gpu_backend_type = "GPU"
                
                # æ£€æŸ¥æ˜¯å¦å·²ç»æµ‹è¯•è¿‡
                if is_test_already_done(model_name, gpu_backend_type, context_length, existing_tests):
                    print(f"\nè¿›åº¦: {current_test}/{total_tests} - â­ï¸ è·³è¿‡å·²å®Œæˆçš„æµ‹è¯•: {model_name} | {gpu_backend_type} | ä¸Šä¸‹æ–‡:{context_length}")
                    skipped_tests += 1
                else:
                    print(f"\nè¿›åº¦: {current_test}/{total_tests}")
                    
                    output, backend_type, n_gen, repetitions = run_benchmark(model_path, context_length, use_gpu=True)
                    if output:
                        results = extract_tokens_per_second(output)
                        print(f"ğŸ“Š {model_name} | {backend_type} | ä¸Šä¸‹æ–‡:{context_length}")
                        for result in results:
                            tokens_per_sec = result.get('avg_ts', 0)
                            phase = result.get('phase', 'unknown')
                            print(f"   {phase}: {tokens_per_sec:.2f} t/s")
                            
                            # ç«‹å³ä¿å­˜åˆ°CSV
                            csv_row = {
                                'model_name': model_name,
                                'backend': backend_type,
                                'n_gen': n_gen,
                                'repetitions': repetitions,
                                'context_length': context_length,
                                'phase': phase,
                                'tokens_per_sec': tokens_per_sec
                            }
                            save_to_csv(csv_row)
                            all_results.append(csv_row)
                    else:
                        print("æœªè·å–åˆ°è¾“å‡ºæ•°æ®")
    
    print(f"\nâœ… å®Œæˆï¼")
    print(f"ğŸ“Š æ–°å¢æµ‹è¯•ç»“æœ: {len(all_results)} æ¡")
    print(f"â­ï¸ è·³è¿‡å·²å®Œæˆæµ‹è¯•: {skipped_tests} ä¸ª")
    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {CSV_FILENAME}")
    
    # ç”ŸæˆMarkdownæŠ¥å‘Š
    md_filename = "report.md"
    print(f"ç”ŸæˆMarkdownæŠ¥å‘Š: {md_filename}")
    
    try:
        # è¯»å–å®Œæ•´çš„CSVæ•°æ®æ¥ç”ŸæˆæŠ¥å‘Š
        csv_data = []
        if os.path.exists(CSV_FILENAME):
            with open(CSV_FILENAME, 'r', encoding='utf-8') as csvfile:
                reader = csv.DictReader(csvfile)
                csv_data = list(reader)
        
        with open(md_filename, 'w', encoding='utf-8') as mdfile:
            mdfile.write("# GGUFæ¨¡å‹åŸºå‡†æµ‹è¯•æŠ¥å‘Š\n\n")
            mdfile.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            mdfile.write(f"**æµ‹è¯•ç›®å½•**: `{MODEL_DIR}`\n\n")
            mdfile.write(f"**ä¸Šä¸‹æ–‡é•¿åº¦**: {', '.join(map(str, CONTEXT_LENGTHS))}\n\n")
            mdfile.write(f"**ç”Ÿæˆtokenæ•°**: {N_GEN}\n\n")
            mdfile.write(f"**é‡å¤æ¬¡æ•°**: {REPETITIONS}\n\n")
            mdfile.write(f"**Flash Attention**: {'å¯ç”¨' if FLASH_ATTN else 'ç¦ç”¨'}\n\n")
            
            mdfile.write("## æµ‹è¯•ç»“æœ\n\n")
            
            # æŒ‰æ¨¡å‹åˆ†ç»„
            models = {}
            for row in csv_data:
                model_name = row['model_name']
                if model_name not in models:
                    models[model_name] = []
                models[model_name].append(row)
            
            # ä¸ºæ¯ä¸ªæ¨¡å‹ç”Ÿæˆä¸€ä¸ªè¡¨æ ¼
            for model_name in sorted(models.keys()):
                mdfile.write(f"### {model_name}\n\n")
                
                # åˆ›å»ºè¡¨æ ¼å¤´
                mdfile.write("| åç«¯ | ä¸Šä¸‹æ–‡é•¿åº¦ | Prompt Processing (t/s) | Token Generation (t/s) |\n")
                mdfile.write("|------|------------|-------------------------|------------------------|\n")
                
                # æŒ‰åç«¯å’Œä¸Šä¸‹æ–‡é•¿åº¦ç»„ç»‡æ•°æ®
                model_data = {}
                for row in models[model_name]:
                    backend = row['backend']
                    context_length = int(row['context_length'])
                    phase = row['phase']
                    tokens_per_sec = float(row['tokens_per_sec'])
                    
                    key = (backend, context_length)
                    if key not in model_data:
                        model_data[key] = {}
                    model_data[key][phase] = tokens_per_sec
                
                # æŒ‰åç«¯å’Œä¸Šä¸‹æ–‡é•¿åº¦æ’åºè¾“å‡º
                for (backend, context_length) in sorted(model_data.keys(), key=lambda x: (x[0], x[1])):
                    data = model_data[(backend, context_length)]
                    pp_speed = data.get('prompt_processing', 'N/A')
                    tg_speed = data.get('token_generation', 'N/A')
                    
                    pp_str = f"{pp_speed:.2f}" if isinstance(pp_speed, (int, float)) else str(pp_speed)
                    tg_str = f"{tg_speed:.2f}" if isinstance(tg_speed, (int, float)) else str(tg_speed)
                    
                    mdfile.write(f"| {backend} | {context_length} | {pp_str} | {tg_str} |\n")
                
                mdfile.write("\n")
            
            # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
            mdfile.write("## æµ‹è¯•ç»Ÿè®¡\n\n")
            mdfile.write(f"- **æ¨¡å‹æ•°é‡**: {len(models)}\n")
            mdfile.write(f"- **ä¸Šä¸‹æ–‡é…ç½®**: {', '.join(map(str, CONTEXT_LENGTHS))}\n")
            mdfile.write(f"- **æ€»æµ‹è¯•è®°å½•**: {len(csv_data)}\n")
            
            # æ€§èƒ½ç»Ÿè®¡
            cpu_speeds = []
            gpu_speeds = []
            for row in csv_data:
                if row['phase'] == 'token_generation':  # åªç»Ÿè®¡token generationæ€§èƒ½
                    speed = float(row['tokens_per_sec'])
                    if row['backend'] == 'CPU':
                        cpu_speeds.append(speed)
                    elif row['backend'] == 'GPU':
                        gpu_speeds.append(speed)
            
            if cpu_speeds:
                mdfile.write(f"- **CPU Token Generationå¹³å‡é€Ÿåº¦**: {sum(cpu_speeds)/len(cpu_speeds):.2f} t/s\n")
                mdfile.write(f"- **CPU Token Generationæœ€é«˜é€Ÿåº¦**: {max(cpu_speeds):.2f} t/s\n")
            
            if gpu_speeds:
                mdfile.write(f"- **GPU Token Generationå¹³å‡é€Ÿåº¦**: {sum(gpu_speeds)/len(gpu_speeds):.2f} t/s\n")
                mdfile.write(f"- **GPU Token Generationæœ€é«˜é€Ÿåº¦**: {max(gpu_speeds):.2f} t/s\n")
            
            # æ·»åŠ æ¨¡å‹å…¼å®¹æ€§ä¿¡æ¯
            mdfile.write("\n## æ¨¡å‹å…¼å®¹æ€§è¯´æ˜\n\n")
            tq_models = [model for model in models.keys() if "TQ" in model.upper()]
            if tq_models:
                mdfile.write("ä»¥ä¸‹æ¨¡å‹åŒ…å«TQé‡åŒ–ï¼Œç”±äºMetalåç«¯å…¼å®¹æ€§é—®é¢˜ï¼Œä»…åœ¨CPUä¸Šæµ‹è¯•ï¼š\n\n")
                for model in sorted(tq_models):
                    mdfile.write(f"- {model}\n")
        
        print("âœ“ MarkdownæŠ¥å‘Šç”ŸæˆæˆåŠŸ")
    except Exception as e:
        print(f"âœ— ç”ŸæˆMarkdownæŠ¥å‘Šå¤±è´¥: {e}")
    
    print(f"\n=== æµ‹è¯•å®Œæˆ ===")
    print(f"ç»“æœæ–‡ä»¶:")
    if os.path.exists(CSV_FILENAME):
        print(f"- {CSV_FILENAME}")
    if os.path.exists(md_filename):
        print(f"- {md_filename}")
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 